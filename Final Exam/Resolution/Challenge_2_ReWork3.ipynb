{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import numpy.random as nr\n",
    "import math\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn import linear_model\n",
    "import sklearn.metrics as sklm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 23)\n",
      "(16749, 24)\n"
     ]
    }
   ],
   "source": [
    "AdvWorksTest = pd.read_csv('AW_test.csv')\n",
    "AdvWorksTrain = pd.read_csv('AdvWorksCusts.csv')\n",
    "AW_BikeBuyer = pd.read_csv('AW_BikeBuyer.csv')\n",
    "\n",
    "AdvWorksTest.columns = [str.replace('-', '_') for str in AdvWorksTest.columns]\n",
    "AdvWorksTrain.columns = [str.replace('-', '_') for str in AdvWorksTrain.columns]\n",
    "\n",
    "for col in AdvWorksTest.columns:\n",
    "    if AdvWorksTest[col].dtype == object:\n",
    "        count = 0\n",
    "        count = [count + 1 for x in AdvWorksTest[col] if x == '?']\n",
    "        #print(col + ' ' + str(sum(count)))\n",
    "        \n",
    "for col in AdvWorksTrain.columns:\n",
    "    if AdvWorksTrain[col].dtype == object:\n",
    "        count = 0\n",
    "        count = [count + 1 for x in AdvWorksTrain[col] if x == '?']\n",
    "        #print(col + ' ' + str(sum(count)))    \n",
    "        \n",
    "AdvWorksTrain = pd.merge(AdvWorksTrain, AW_BikeBuyer)        \n",
    "        \n",
    "print(AdvWorksTest.shape)  \n",
    "print(AdvWorksTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16749, 21)\n",
      "(500, 20)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def age_customer(dl):\n",
    "    Db = datetime.strptime(dl, '%m/%d/%Y')\n",
    "    dl = datetime.strptime('1998-01-01', '%Y-%m-%d').year - Db.year\n",
    " \n",
    "    if dl > 45: return 'Above 55'\n",
    "    elif 45 < dl <= 55: return 'Between 45 and 55'\n",
    "    elif 25 < dl <= 45: return 'Between 25 and 45'\n",
    "    elif 0 < dl <= 25: return 'Under 25'\n",
    "    else: return 'None'\n",
    "    \n",
    "def age_customer_train(dl):\n",
    "    Db = datetime.strptime(dl, '%Y-%m-%d')\n",
    "    dl = datetime.strptime('1998-01-01', '%Y-%m-%d').year - Db.year\n",
    " \n",
    "    if dl > 45: return 'Above 55'\n",
    "    elif 45 < dl <= 55: return 'Between 45 and 55'\n",
    "    elif 25 < dl <= 45: return 'Between 25 and 45'\n",
    "    elif 0 < dl <= 25: return 'Under 25'\n",
    "    else: return 'None'    \n",
    "\n",
    "AdvWorksTest['GroupCustomers']  = AdvWorksTest.BirthDate.apply (lambda row: age_customer(row))  \n",
    "AdvWorksTrain['GroupCustomers'] = AdvWorksTrain.BirthDate.apply (lambda row: age_customer_train(row))  \n",
    "\n",
    "AdvWorksTest.drop('Title', axis = 1, inplace = True)\n",
    "AdvWorksTest.drop('Suffix', axis = 1, inplace = True)\n",
    "AdvWorksTest.drop('AddressLine2', axis = 1, inplace = True)\n",
    "AdvWorksTest.drop('MiddleName', axis = 1, inplace = True)\n",
    "AdvWorksTrain.drop('Title', axis = 1, inplace = True)\n",
    "AdvWorksTrain.drop('Suffix', axis = 1, inplace = True)\n",
    "AdvWorksTrain.drop('AddressLine2', axis = 1, inplace = True)\n",
    "AdvWorksTrain.drop('MiddleName', axis = 1, inplace = True)\n",
    "\n",
    "print(AdvWorksTrain.shape)\n",
    "print(AdvWorksTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdvWorksTrain = AdvWorksTrain.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "AdvWorksTest = AdvWorksTest.apply(lambda x:x.fillna(x.value_counts().index[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(AdvWorksTrain['BikeBuyer'])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16749, 12)\n",
      "[[0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "def encode_string(cat_features):\n",
    "    ## First encode the strings to numeric categories\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    enc.fit(cat_features)\n",
    "    enc_cat_features = enc.transform(cat_features)\n",
    "    ## Now, apply one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    encoded = ohe.fit(enc_cat_features.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_features.reshape(-1,1)).toarray()\n",
    "\n",
    "categorical_columns = ['Occupation','Gender','MaritalStatus']\n",
    "\n",
    "Features = encode_string(AdvWorksTrain['GroupCustomers'])\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(AdvWorksTrain[col])\n",
    "    Features = np.concatenate([Features, temp], axis = 1)\n",
    "\n",
    "print(Features.shape)\n",
    "print(Features[:2, :])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16749, 16)\n",
      "[[0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 1.00000e+00 0.00000e+00\n",
      "  0.00000e+00 0.00000e+00 1.37947e+05 2.00000e+00]\n",
      " [0.00000e+00 1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00\n",
      "  1.00000e+00 0.00000e+00 0.00000e+00 1.00000e+00 0.00000e+00 1.00000e+00\n",
      "  1.00000e+00 3.00000e+00 1.01141e+05 3.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "FeaturesTrain = np.concatenate([Features, np.array(AdvWorksTrain[['NumberCarsOwned','NumberChildrenAtHome'\n",
    "                                                              ,'YearlyIncome','TotalChildren']])], axis = 1)\n",
    "print(FeaturesTrain.shape)\n",
    "print(FeaturesTrain[:2, :])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Randomly sample cases to create independent training and test data\n",
    "nr.seed(9988)\n",
    "indx = range(FeaturesTrain.shape[0])\n",
    "indx = ms.train_test_split(indx, test_size = 300)\n",
    "\n",
    "X_train = FeaturesTrain[indx[0],:]\n",
    "y_train = np.ravel(labels[indx[0]])\n",
    "X_test = FeaturesTrain[indx[1],:]\n",
    "y_test = np.ravel(labels[indx[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_mod = linear_model.LogisticRegression() \n",
    "logistic_mod.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logistic_mod.predict(X_test)\n",
    "#print(classification_report(y_test, y_pred, target_names=['Y', 'N']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.75626405 0.24373595]\n",
      " [0.6314472  0.3685528 ]\n",
      " [0.63778531 0.36221469]\n",
      " [0.6443431  0.3556569 ]\n",
      " [0.60207408 0.39792592]\n",
      " [0.51562483 0.48437517]\n",
      " [0.63637515 0.36362485]\n",
      " [0.71187281 0.28812719]\n",
      " [0.70187592 0.29812408]\n",
      " [0.66281141 0.33718859]\n",
      " [0.50203852 0.49796148]\n",
      " [0.53107537 0.46892463]\n",
      " [0.66041148 0.33958852]\n",
      " [0.64212884 0.35787116]\n",
      " [0.66695967 0.33304033]]\n"
     ]
    }
   ],
   "source": [
    "probabilities = logistic_mod.predict_proba(X_test)\n",
    "print(probabilities[:15,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[1 0 0 0 0 0 0 0 0 0 1 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "def score_model(probs, threshold):\n",
    "    return np.array([1 if x > threshold else 0 for x in probs[:,1]])\n",
    "scores = score_model(probabilities, 0.50)\n",
    "print(np.array(scores[:15]))\n",
    "print(y_test[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Confusion matrix\n",
      "                 Score positive    Score negative\n",
      "Actual positive       203                11\n",
      "Actual negative        54                32\n",
      "\n",
      "Accuracy  0.78\n",
      " \n",
      "           Positive      Negative\n",
      "Num case      214            86\n",
      "Precision    0.79          0.74\n",
      "Recall       0.95          0.37\n",
      "F1           0.86          0.50\n"
     ]
    }
   ],
   "source": [
    "def print_metrics(labels, scores):\n",
    "    metrics = sklm.precision_recall_fscore_support(labels, scores)\n",
    "    conf = sklm.confusion_matrix(labels, scores)\n",
    "    print('                 Confusion matrix')\n",
    "    print('                 Score positive    Score negative')\n",
    "    print('Actual positive    %6d' % conf[0,0] + '             %5d' % conf[0,1])\n",
    "    print('Actual negative    %6d' % conf[1,0] + '             %5d' % conf[1,1])\n",
    "    print('')\n",
    "    print('Accuracy  %0.2f' % sklm.accuracy_score(labels, scores))\n",
    "    print(' ')\n",
    "    print('           Positive      Negative')\n",
    "    print('Num case   %6d' % metrics[3][0] + '        %6d' % metrics[3][1])\n",
    "    print('Precision  %6.2f' % metrics[0][0] + '        %6.2f' % metrics[0][1])\n",
    "    print('Recall     %6.2f' % metrics[1][0] + '        %6.2f' % metrics[1][1])\n",
    "    print('F1         %6.2f' % metrics[2][0] + '        %6.2f' % metrics[2][1])\n",
    "\n",
    "  \n",
    "print_metrics(y_test, scores)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 3)\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def encode_string(cat_features):\n",
    "    ## First encode the strings to numeric categories\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    enc.fit(cat_features)\n",
    "    enc_cat_features = enc.transform(cat_features)\n",
    "    ## Now, apply one hot encoding\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    encoded = ohe.fit(enc_cat_features.reshape(-1,1))\n",
    "    return encoded.transform(enc_cat_features.reshape(-1,1)).toarray()\n",
    "\n",
    "categorical_columns = ['Occupation','Gender','MaritalStatus']\n",
    "\n",
    "FeaturesTest = encode_string(AdvWorksTest['GroupCustomers'])\n",
    "for col in categorical_columns:\n",
    "    temp = encode_string(AdvWorksTest[col])\n",
    "    Features = np.concatenate([FeaturesTest, temp], axis = 1)\n",
    "\n",
    "print(FeaturesTest.shape)\n",
    "print(FeaturesTest[:2, :])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 7)\n",
      "[[1.00000e+00 0.00000e+00 0.00000e+00 2.00000e+00 0.00000e+00 8.69310e+04\n",
      "  5.00000e+00]\n",
      " [0.00000e+00 1.00000e+00 0.00000e+00 2.00000e+00 2.00000e+00 1.00125e+05\n",
      "  4.00000e+00]]\n"
     ]
    }
   ],
   "source": [
    "FeaturesTest = np.concatenate([FeaturesTest, np.array(AdvWorksTest[['NumberCarsOwned','NumberChildrenAtHome'\n",
    "                                                              ,'YearlyIncome','TotalChildren']])], axis = 1)\n",
    "print(FeaturesTest.shape)\n",
    "print(FeaturesTest[:2, :])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000e+00, 0.00000e+00, 0.00000e+00, 2.00000e+00, 0.00000e+00,\n",
       "        8.69310e+04, 5.00000e+00],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, 2.00000e+00, 2.00000e+00,\n",
       "        1.00125e+05, 4.00000e+00],\n",
       "       [1.00000e+00, 0.00000e+00, 0.00000e+00, 2.00000e+00, 0.00000e+00,\n",
       "        1.03985e+05, 4.00000e+00],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00,\n",
       "        1.27161e+05, 4.00000e+00],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00, 2.00000e+00,\n",
       "        2.18760e+04, 2.00000e+00],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00, 0.00000e+00,\n",
       "        4.44670e+04, 1.00000e+00],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, 2.00000e+00, 2.00000e+00,\n",
       "        7.77020e+04, 4.00000e+00],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, 3.00000e+00, 4.00000e+00,\n",
       "        9.94180e+04, 4.00000e+00],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00, 4.00000e+00,\n",
       "        1.35220e+04, 4.00000e+00],\n",
       "       [0.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        4.62640e+04, 1.00000e+00],\n",
       "       [0.00000e+00, 1.00000e+00, 0.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        9.63750e+04, 2.00000e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeaturesTest[:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic_mod.predict(FeaturesTest[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
